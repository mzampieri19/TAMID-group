{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # type: ignore\n",
    "from tensorflow.keras.models import load_model # type: ignore\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import EfficientNetB0 # type: ignore\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization # type: ignore\n",
    "from tensorflow.keras.models import Model # type: ignore\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '/Users/michelangelozampieri/Desktop/plastics_CNN/seven_plastics'\n",
    "TEST_DIR = '/Users/michelangelozampieri/Desktop/plastics_CNN/seven_plastics_test'\n",
    "IMG_SIZE = (244, 244)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 8\n",
    "EPOCHS_INITIAL = 5\n",
    "EPOCHS_FINE_TUNE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed!\n"
     ]
    }
   ],
   "source": [
    "test_split_ratio = .3\n",
    "\n",
    "# Create the test directory if it doesn't exist\n",
    "os.makedirs(TEST_DIR, exist_ok=True)\n",
    "\n",
    "# Iterate through each category in the training directory\n",
    "for category in os.listdir(TRAIN_DIR):\n",
    "    category_path = os.path.join(TRAIN_DIR, category)\n",
    "    if os.path.isdir(category_path):\n",
    "        # Create a corresponding category directory in the test directory\n",
    "        test_category_path = os.path.join(TEST_DIR, category)\n",
    "        os.makedirs(test_category_path, exist_ok=True)\n",
    "\n",
    "        # Get all image files in the category\n",
    "        images = [f for f in os.listdir(category_path) if os.path.isfile(os.path.join(category_path, f))]\n",
    "        \n",
    "        # Randomly select a subset of images for testing\n",
    "        num_test_images = int(len(images) * test_split_ratio)\n",
    "        test_images = random.sample(images, num_test_images)\n",
    "\n",
    "        # Move the selected images to the test directory\n",
    "        for image in test_images:\n",
    "            src_path = os.path.join(category_path, image)\n",
    "            dest_path = os.path.join(test_category_path, image)\n",
    "            shutil.move(src_path, dest_path)\n",
    "\n",
    "print(\"Dataset split completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4_low_density_polyethylene_PE-LD', '8_no_plastic', '3_polyvinylchloride_PVC', '1_polyethylene_PET', '6_polystyrene_PS', '5_polypropylene_PP', '7_other_resins', '2_high_density_polyethylene_PE-HD']\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all categories (subdirectories) in TRAIN_DIR\n",
    "categories = [d for d in os.listdir(TRAIN_DIR) if os.path.isdir(os.path.join(TRAIN_DIR, d))]\n",
    "\n",
    "# Remove hidden files like .DS_Store\n",
    "categories = [c for c in categories if not c.startswith(\".\")]\n",
    "\n",
    "# Get a list of all categories (subdirectories) in TRAIN_DIR\n",
    "categories = [entry.name for entry in os.scandir(TRAIN_DIR) if entry.is_dir()]\n",
    "\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
    "    rotation_range=40,  # Randomly rotate images by up to 40 degrees\n",
    "    width_shift_range=0.2,  # Randomly shift images horizontally by 20%\n",
    "    height_shift_range=0.2,  # Randomly shift images vertically by 20%\n",
    "    shear_range=0.2,  # Randomly apply shearing transformations\n",
    "    zoom_range=0.2,  # Randomly zoom in/out on images\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    fill_mode='nearest'  # Fill in missing pixels after transformations\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48 files belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 294 files belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    labels=\"inferred\",  # Ensure labels are inferred from subdirectories\n",
    "    label_mode=\"categorical\",  # Use categorical labels for multi-class classification\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    TEST_DIR,\n",
    "    labels=\"inferred\",  # Ensure labels are inferred from subdirectories\n",
    "    label_mode=\"categorical\",  # Use categorical labels for validation\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(244, 244, 3))\n",
    "base_model.trainable = False  # Initially freeze the base model\n",
    "\n",
    "# Custom classification head\n",
    "x = GlobalAveragePooling2D()(base_model.output)  # Reduce feature maps to a single vector\n",
    "x = Dense(64, activation=\"relu\")(x)  # Fewer neurons for simplicity\n",
    "x = BatchNormalization()(x)  # Optional: Stabilize training\n",
    "output_layer = Dense(NUM_CLASSES, activation=\"softmax\")(x)  # Output layer\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=base_model.input, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.1493 - loss: 2.5234\n",
      "Epoch 2/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 0.5764 - loss: 1.2512\n",
      "Epoch 3/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238ms/step - accuracy: 0.7778 - loss: 0.6973\n",
      "Epoch 4/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 230ms/step - accuracy: 0.8889 - loss: 0.5522\n",
      "Epoch 5/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303ms/step - accuracy: 0.9375 - loss: 0.3675\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Compile and Train (Feature Extraction Phase)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train for a few epochs with frozen base model\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS_INITIAL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"plastics_model_v1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 5s/step - accuracy: 0.3450 - loss: 1.7747\n",
      "Validation accuracy: 0.35374149680137634\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Validation accuracy: {val_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
