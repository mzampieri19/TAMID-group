{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # type: ignore\n",
    "\n",
    "model = keras.models.load_model('plastics_model_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '/Users/michelangelozampieri/Desktop/plastics_CNN/seven_plastics'\n",
    "TEST_DIR = '/Users/michelangelozampieri/Desktop/plastics_CNN/seven_plastics_test'\n",
    "IMG_SIZE = (244, 244)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 8\n",
    "EPOCHS_FINE_TUNE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
    "    rotation_range=40,  # Randomly rotate images by up to 40 degrees\n",
    "    width_shift_range=0.2,  # Randomly shift images horizontally by 20%\n",
    "    height_shift_range=0.2,  # Randomly shift images vertically by 20%\n",
    "    shear_range=0.2,  # Randomly apply shearing transformations\n",
    "    zoom_range=0.2,  # Randomly zoom in/out on images\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    fill_mode='nearest'  # Fill in missing pixels after transformations\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48 files belonging to 8 classes.\n",
      "Found 294 files belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    labels=\"inferred\",  # Ensure labels are inferred from subdirectories\n",
    "    label_mode=\"categorical\",  # Use categorical labels for multi-class classification\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    TEST_DIR,\n",
    "    labels=\"inferred\",  # Ensure labels are inferred from subdirectories\n",
    "    label_mode=\"categorical\",  # Use categorical labels for validation\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16s/step - accuracy: 0.9618 - loss: 0.2925 - val_accuracy: 0.3537 - val_loss: 1.7933\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.9271 - loss: 0.3061 - val_accuracy: 0.3537 - val_loss: 1.7906\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.9757 - loss: 0.2691 - val_accuracy: 0.3605 - val_loss: 1.7874\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4s/step - accuracy: 0.9861 - loss: 0.2625 - val_accuracy: 0.3605 - val_loss: 1.7844\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.2733 - val_accuracy: 0.3605 - val_loss: 1.7819\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.2800 - val_accuracy: 0.3639 - val_loss: 1.7792\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4s/step - accuracy: 0.9132 - loss: 0.3645 - val_accuracy: 0.3639 - val_loss: 1.7761\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4s/step - accuracy: 0.9618 - loss: 0.2624 - val_accuracy: 0.3605 - val_loss: 1.7733\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5s/step - accuracy: 0.9861 - loss: 0.2534 - val_accuracy: 0.3673 - val_loss: 1.7707\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4s/step - accuracy: 0.9757 - loss: 0.2500 - val_accuracy: 0.3776 - val_loss: 1.7682\n"
     ]
    }
   ],
   "source": [
    "model.trainable = True\n",
    "for layer in model.layers[:-20]:  # Freeze all layers except the last 20\n",
    "    layer.trainable = False\n",
    "\n",
    "# Use a lower learning rate for fine-tuning\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "# Recompile model\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train again with fine-tuning\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=EPOCHS_FINE_TUNE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('plastics_model_v2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 450ms/step - accuracy: 0.4084 - loss: 1.7465\n",
      "Validation accuracy: 0.37755101919174194\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Validation accuracy: {val_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
